{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3403ogDoEkqbZl5HCNON7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrao1/AI-ML/blob/main/SampleChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h3vQh7t_7wiv",
        "outputId": "6069a165-c1c9-41a7-bee9-ef2b010fb2f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3d53064a1ac5>:56: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  if nlp(synonym).similarity(doc) >= 0.8:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: Hi there\n",
            "Intents: defaultdict(<class 'float'>, {'greeting': 1.0})\n",
            "\n",
            "Message: I want to buy a car\n",
            "Intents: defaultdict(<class 'float'>, {'buy_car': 1.0})\n",
            "\n",
            "Message: Can you help me book a flight?\n",
            "Intents: defaultdict(<class 'float'>, {'book_flight': 1.0})\n",
            "\n",
            "Message: I want to purchase a vehicle\n",
            "Intents: defaultdict(<class 'float'>, {'buy_car': 1.0})\n",
            "\n",
            "Message: I'm looking reserve a flight\n",
            "Intents: defaultdict(<class 'float'>, {'book_flight': 1.0})\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from collections import defaultdict\n",
        "\n",
        "# Define intents and their corresponding patterns purchase a vehicle\n",
        "intents = {\n",
        "      \"greeting\": [{\"LOWER\": \"hi\"}, {\"LOWER\": \"there\"}]\n",
        "}\n",
        "\n",
        "buy_car = [\n",
        "    [{\"LOWER\": \"buy\"}, {\"POS\": \"DET\"}, {\"LOWER\": \"car\"}],\n",
        "    [{\"LOWER\": \"purchase\"}, {\"POS\": \"DET\"}, {\"LOWER\": \"vehicle\"}]\n",
        "]\n",
        "book_flight = [\n",
        "    [{\"LOWER\": \"book\"}, {\"POS\": \"DET\"}, {\"LOWER\": \"flight\"}],\n",
        "    [{\"LOWER\": \"reserve\"}, {\"POS\": \"DET\"}, {\"LOWER\": \"flight\"}]\n",
        "]\n",
        "\n",
        "#Define synonyms for each intent\n",
        "synonyms = {\n",
        "    \"buy_car\": [\"purchase car\", \"get a car\", \"buy vehicle\"],\n",
        "    \"book_flight\": [\"reserve flight\", \"book airfare\", \"buy plane ticket\"],\n",
        "    \"greeting\": [\"Hi\", \"hi\"]\n",
        "}\n",
        "\n",
        "#Initialize Spacy Language model and matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "messages =[\n",
        "    \"Hi there\",\n",
        "    \"I want to buy a car\",\n",
        "    \"Can you help me book a flight?\",\n",
        "    \"I want to purchase a vehicle\",\n",
        "    \"I'm looking reserve a flight\"\n",
        "]\n",
        "\n",
        "#Add patterns for each intent to the matcher\n",
        "matcher.add(\"buy_car\", buy_car)\n",
        "matcher.add(\"book_flight\", book_flight)\n",
        "\n",
        "for intent, patterns in intents.items():\n",
        "    matcher.add(intent, [patterns])\n",
        "\n",
        "#Define function to extract itents from user message\n",
        "def extract_intents(message):\n",
        "  doc = nlp(message)\n",
        "  matches = matcher(doc)\n",
        "  intents = defaultdict(float)\n",
        "  for match_id, start, end in matches:\n",
        "    intent = nlp.vocab.strings[match_id]\n",
        "    intents[intent] += 1\n",
        "\n",
        "  for intent, synonyms_list in synonyms.items():\n",
        "    for synonym in synonyms_list:\n",
        "      if nlp(synonym).similarity(doc) >= 0.8:\n",
        "        intents[intent] += 0.5\n",
        "\n",
        "  return intents\n",
        "\n",
        "#Process messages and find matches\n",
        "for msg in messages:\n",
        "  intents = extract_intents(msg)\n",
        "  print(f\"Message: {msg}\")\n",
        "  print(f\"Intents: {intents}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fQzGsd9E_9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}